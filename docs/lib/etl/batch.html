<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>lib.etl.batch API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>lib.etl.batch</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># sys libs
from io import StringIO


class InsertBatch:
    &#34;&#34;&#34;
    This class defines a batch processing object that can be
    used to insert data into the Apache Cassandra tables.

    See Also:

    `https://docs.datastax.com/en/cql-oss/3.3/cql/cql_using/useBatchGoodExample.html`: DataStax documentation on batch statement.
    &#34;&#34;&#34;

    def __init__(self, session, inserts, max_size=250):
        &#34;&#34;&#34;
        The constructor instantiates a batch object with the following arguments:

        Args:

        `session`: Cassandra session object.
        `inserts`: List of insert statement builders per table.
        `max_size`: The maximum number of rows to be inserted by each commit.
        &#34;&#34;&#34;
        self.session = session

        self.buffers = [None] * len(inserts)
        self.inserts = inserts

        self.max_size = max_size
        self.size = 0

    def __begin_batch(self):
        &#34;&#34;&#34;
        Initializes the StringIO buffer for each table batch object
        and writes the BEGIN BATCH statement.
        &#34;&#34;&#34;
        for index, buffer in enumerate(self.buffers):
            self.buffers[index] = StringIO()
            self.buffers[index].write(&#34;BEGIN BATCH\n&#34;)

    def __commit_batch(self):
        &#34;&#34;&#34;
        Commits each table batch following the steps below:

        - Writes the APPLY BATCH statement.
        - Sets the StringIO buffer cursor to the beginning of the buffer.
        - Executes the batch statements using Cassandra&#39;s session method.
        - Closes the StringIO buffer.
        - Clears the batches array.
        - Resets the batch size counter.
        &#34;&#34;&#34;
        for buffer in self.buffers:
            try:
                buffer.write(&#39;APPLY BATCH;\n&#39;)
                buffer.seek(0)
                self.session.execute(buffer.read())
                buffer.close()
            except Exception as e:
                print(e)

        self.buffers = [None] * len(self.inserts)
        self.size = 0

    def __write(self, values):
        &#34;&#34;&#34;
        Maps the data input for each table insert statement and
        writes to the corresponding StringIO buffer.

        Args:

        `values`: The data input to write as a SQL insert.
        &#34;&#34;&#34;
        for index, buffer in enumerate(self.buffers):
            buffer.write(self.inserts[index].to_sql(values))

    def commit(self, close=False):
        &#34;&#34;&#34;
        This method must be called at the end of the processing
        to commit the last batch of insert instructions.
        Once the batch has not reached the maximum size
        to be automatically committed by the insertion method.

        Args:

        `close`: If True, closes the session.
        &#34;&#34;&#34;
        self.__commit_batch()
        if close:
            self.session.shutdown()
            self.session.close()
            self.session = None

    def write(self, values):
        &#34;&#34;&#34;
        Writes the data input into the the batch buffer as an insert statement.
        If the batch size is equal to the maximum size, the batch is committed
        and the buffer is cleared.

        Args:

        `values`: The data input to write as a SQL insert.
        &#34;&#34;&#34;
        if self.size == 0:
            self.__begin_batch()

        if self.size &lt; self.max_size:
            self.__write(values)
            self.size += 1
        else:
            self.__write(values)
            self.__commit_batch()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="lib.etl.batch.InsertBatch"><code class="flex name class">
<span>class <span class="ident">InsertBatch</span></span>
<span>(</span><span>session, inserts, max_size=250)</span>
</code></dt>
<dd>
<div class="desc"><p>This class defines a batch processing object that can be
used to insert data into the Apache Cassandra tables.</p>
<p>See Also:</p>
<p><code>&lt;https://docs.datastax.com/en/cql-oss/3.3/cql/cql_using/useBatchGoodExample.html</code>:&gt; DataStax documentation on batch statement.</p>
<p>The constructor instantiates a batch object with the following arguments:</p>
<p>Args:</p>
<p><code>session</code>: Cassandra session object.
<code>inserts</code>: List of insert statement builders per table.
<code>max_size</code>: The maximum number of rows to be inserted by each commit.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class InsertBatch:
    &#34;&#34;&#34;
    This class defines a batch processing object that can be
    used to insert data into the Apache Cassandra tables.

    See Also:

    `https://docs.datastax.com/en/cql-oss/3.3/cql/cql_using/useBatchGoodExample.html`: DataStax documentation on batch statement.
    &#34;&#34;&#34;

    def __init__(self, session, inserts, max_size=250):
        &#34;&#34;&#34;
        The constructor instantiates a batch object with the following arguments:

        Args:

        `session`: Cassandra session object.
        `inserts`: List of insert statement builders per table.
        `max_size`: The maximum number of rows to be inserted by each commit.
        &#34;&#34;&#34;
        self.session = session

        self.buffers = [None] * len(inserts)
        self.inserts = inserts

        self.max_size = max_size
        self.size = 0

    def __begin_batch(self):
        &#34;&#34;&#34;
        Initializes the StringIO buffer for each table batch object
        and writes the BEGIN BATCH statement.
        &#34;&#34;&#34;
        for index, buffer in enumerate(self.buffers):
            self.buffers[index] = StringIO()
            self.buffers[index].write(&#34;BEGIN BATCH\n&#34;)

    def __commit_batch(self):
        &#34;&#34;&#34;
        Commits each table batch following the steps below:

        - Writes the APPLY BATCH statement.
        - Sets the StringIO buffer cursor to the beginning of the buffer.
        - Executes the batch statements using Cassandra&#39;s session method.
        - Closes the StringIO buffer.
        - Clears the batches array.
        - Resets the batch size counter.
        &#34;&#34;&#34;
        for buffer in self.buffers:
            try:
                buffer.write(&#39;APPLY BATCH;\n&#39;)
                buffer.seek(0)
                self.session.execute(buffer.read())
                buffer.close()
            except Exception as e:
                print(e)

        self.buffers = [None] * len(self.inserts)
        self.size = 0

    def __write(self, values):
        &#34;&#34;&#34;
        Maps the data input for each table insert statement and
        writes to the corresponding StringIO buffer.

        Args:

        `values`: The data input to write as a SQL insert.
        &#34;&#34;&#34;
        for index, buffer in enumerate(self.buffers):
            buffer.write(self.inserts[index].to_sql(values))

    def commit(self, close=False):
        &#34;&#34;&#34;
        This method must be called at the end of the processing
        to commit the last batch of insert instructions.
        Once the batch has not reached the maximum size
        to be automatically committed by the insertion method.

        Args:

        `close`: If True, closes the session.
        &#34;&#34;&#34;
        self.__commit_batch()
        if close:
            self.session.shutdown()
            self.session.close()
            self.session = None

    def write(self, values):
        &#34;&#34;&#34;
        Writes the data input into the the batch buffer as an insert statement.
        If the batch size is equal to the maximum size, the batch is committed
        and the buffer is cleared.

        Args:

        `values`: The data input to write as a SQL insert.
        &#34;&#34;&#34;
        if self.size == 0:
            self.__begin_batch()

        if self.size &lt; self.max_size:
            self.__write(values)
            self.size += 1
        else:
            self.__write(values)
            self.__commit_batch()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="lib.etl.batch.InsertBatch.commit"><code class="name flex">
<span>def <span class="ident">commit</span></span>(<span>self, close=False)</span>
</code></dt>
<dd>
<div class="desc"><p>This method must be called at the end of the processing
to commit the last batch of insert instructions.
Once the batch has not reached the maximum size
to be automatically committed by the insertion method.</p>
<p>Args:</p>
<p><code>close</code>: If True, closes the session.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def commit(self, close=False):
    &#34;&#34;&#34;
    This method must be called at the end of the processing
    to commit the last batch of insert instructions.
    Once the batch has not reached the maximum size
    to be automatically committed by the insertion method.

    Args:

    `close`: If True, closes the session.
    &#34;&#34;&#34;
    self.__commit_batch()
    if close:
        self.session.shutdown()
        self.session.close()
        self.session = None</code></pre>
</details>
</dd>
<dt id="lib.etl.batch.InsertBatch.write"><code class="name flex">
<span>def <span class="ident">write</span></span>(<span>self, values)</span>
</code></dt>
<dd>
<div class="desc"><p>Writes the data input into the the batch buffer as an insert statement.
If the batch size is equal to the maximum size, the batch is committed
and the buffer is cleared.</p>
<p>Args:</p>
<p><code>values</code>: The data input to write as a SQL insert.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write(self, values):
    &#34;&#34;&#34;
    Writes the data input into the the batch buffer as an insert statement.
    If the batch size is equal to the maximum size, the batch is committed
    and the buffer is cleared.

    Args:

    `values`: The data input to write as a SQL insert.
    &#34;&#34;&#34;
    if self.size == 0:
        self.__begin_batch()

    if self.size &lt; self.max_size:
        self.__write(values)
        self.size += 1
    else:
        self.__write(values)
        self.__commit_batch()</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="lib.etl" href="index.html">lib.etl</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="lib.etl.batch.InsertBatch" href="#lib.etl.batch.InsertBatch">InsertBatch</a></code></h4>
<ul class="">
<li><code><a title="lib.etl.batch.InsertBatch.commit" href="#lib.etl.batch.InsertBatch.commit">commit</a></code></li>
<li><code><a title="lib.etl.batch.InsertBatch.write" href="#lib.etl.batch.InsertBatch.write">write</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>